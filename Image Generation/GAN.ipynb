{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PNBe9f4QgOul"
      },
      "outputs": [],
      "source": [
        "# 1.1 Importing Libraries\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2 Setting up Device\n",
        "\n",
        "# Enable anomaly detection to track in-place operation errors\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "# Ensure that the results directory exists\n",
        "os.makedirs(\"./results\", exist_ok=True)\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg5Ve9zWiQZL",
        "outputId": "fdf3710e-a977-4cb4-facf-bb6baf9bcff2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.3 Data Loading and Preprocessing\n",
        "batchSize = 64       # Batch size\n",
        "imageSize = 64       # Image size (64x64)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(imageSize),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "dataset = dset.CIFAR10(root='./data', download=True, transform=transform)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6nsQCX-iV9y",
        "outputId": "ecf516cc-0026-4b48-9969-e341bec938de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 43762098.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.4 Model Definition\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=False),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=False),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=False),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=False),\n",
        "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input).view(-1)\n",
        "\n",
        "# Initialize models\n",
        "netG = Generator().to(device)\n",
        "netG.apply(weights_init)\n",
        "netD = Discriminator().to(device)\n",
        "netD.apply(weights_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJyrMDteiYeG",
        "outputId": "091bfa68-c2dc-4eec-db59-2b1e22b763d7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (main): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2)\n",
              "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2)\n",
              "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): LeakyReLU(negative_slope=0.2)\n",
              "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): LeakyReLU(negative_slope=0.2)\n",
              "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "    (12): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.5 Optimizer and Loss Function\n",
        "criterion = nn.BCELoss()\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "id": "MDNGcOGTicwa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.6 Training Loop\n",
        "for epoch in range(25):\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        netD.zero_grad()\n",
        "        real_images, _ = data\n",
        "        real_images = real_images.to(device)\n",
        "        batch_size = real_images.size(0)\n",
        "\n",
        "        # Create real labels with label smoothing and noise\n",
        "        real_label_noise = torch.rand(batch_size, device=device) * 0.1  # Small random noise\n",
        "        label_real = torch.full((batch_size,), 0.9, dtype=torch.float, device=device) - real_label_noise\n",
        "\n",
        "        # Forward pass real batch through Discriminator\n",
        "        output_real = netD(real_images)\n",
        "        errD_real = criterion(output_real, label_real)\n",
        "\n",
        "        # Generate fake images from the Generator\n",
        "        noise = torch.randn(batch_size, 100, 1, 1, device=device)  # nz = 100\n",
        "        fake_images = netG(noise)\n",
        "\n",
        "        # Create fake labels with noise\n",
        "        fake_label_noise = torch.rand(batch_size, device=device) * 0.1\n",
        "        label_fake = torch.full((batch_size,), 0.0, dtype=torch.float, device=device) + fake_label_noise\n",
        "\n",
        "        # Forward pass fake batch through Discriminator\n",
        "        output_fake = netD(fake_images.detach())\n",
        "        errD_fake = criterion(output_fake, label_fake)\n",
        "\n",
        "        # Backpropagation and optimization for Discriminator\n",
        "        errD = errD_real + errD_fake\n",
        "        errD.backward()\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "\n",
        "        # Generator wants to fool the discriminator, so labels are real\n",
        "        output = netD(fake_images)\n",
        "        errG = criterion(output, label_real)  # Use the same real labels for generator\n",
        "\n",
        "        # Backpropagation and optimization for Generator\n",
        "        errG.backward()\n",
        "        optimizerG.step()\n",
        "\n",
        "        # Print progress\n",
        "        if i % 100 == 0:\n",
        "            print(f'[{epoch}/{25}][{i}/{len(dataloader)}] Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f}')\n",
        "\n",
        "        # Save results every 100 steps\n",
        "        if i % 100 == 0:\n",
        "            vutils.save_image(real_images, f\"./results/real_samples.png\", normalize=True)\n",
        "            vutils.save_image(fake_images.detach(), f\"./results/fake_samples_epoch_{epoch:03d}.png\", normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T99xzDyvifd0",
        "outputId": "24213158-9b55-4f8a-d070-94dd45bf6152"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0/25][0/782] Loss_D: 1.6311 Loss_G: 2.7602\n",
            "[0/25][100/782] Loss_D: 1.2368 Loss_G: 14.0166\n",
            "[0/25][200/782] Loss_D: 0.9884 Loss_G: 1.2956\n",
            "[0/25][300/782] Loss_D: 1.0515 Loss_G: 2.4273\n",
            "[0/25][400/782] Loss_D: 0.7718 Loss_G: 2.9010\n",
            "[0/25][500/782] Loss_D: 1.2904 Loss_G: 0.8423\n",
            "[0/25][600/782] Loss_D: 1.0965 Loss_G: 2.2169\n",
            "[0/25][700/782] Loss_D: 1.0003 Loss_G: 2.5128\n",
            "[1/25][0/782] Loss_D: 1.0156 Loss_G: 2.9717\n",
            "[1/25][100/782] Loss_D: 0.8505 Loss_G: 2.3725\n",
            "[1/25][200/782] Loss_D: 0.8132 Loss_G: 2.1519\n",
            "[1/25][300/782] Loss_D: 0.8573 Loss_G: 2.1648\n",
            "[1/25][400/782] Loss_D: 0.9694 Loss_G: 2.9942\n",
            "[1/25][500/782] Loss_D: 1.0387 Loss_G: 1.9655\n",
            "[1/25][600/782] Loss_D: 1.1342 Loss_G: 1.4300\n",
            "[1/25][700/782] Loss_D: 0.9417 Loss_G: 1.9331\n",
            "[2/25][0/782] Loss_D: 1.0289 Loss_G: 2.7229\n",
            "[2/25][100/782] Loss_D: 1.1840 Loss_G: 1.0380\n",
            "[2/25][200/782] Loss_D: 1.1741 Loss_G: 1.4559\n",
            "[2/25][300/782] Loss_D: 0.8427 Loss_G: 2.4825\n",
            "[2/25][400/782] Loss_D: 0.8758 Loss_G: 2.4109\n",
            "[2/25][500/782] Loss_D: 1.0467 Loss_G: 1.8908\n",
            "[2/25][600/782] Loss_D: 0.9424 Loss_G: 1.4962\n",
            "[2/25][700/782] Loss_D: 0.9228 Loss_G: 2.2380\n",
            "[3/25][0/782] Loss_D: 1.1465 Loss_G: 2.0442\n",
            "[3/25][100/782] Loss_D: 1.2428 Loss_G: 1.0728\n",
            "[3/25][200/782] Loss_D: 1.1313 Loss_G: 1.8726\n",
            "[3/25][300/782] Loss_D: 1.0244 Loss_G: 1.5642\n",
            "[3/25][400/782] Loss_D: 1.1698 Loss_G: 1.1658\n",
            "[3/25][500/782] Loss_D: 1.0342 Loss_G: 1.4514\n",
            "[3/25][600/782] Loss_D: 1.0652 Loss_G: 1.3882\n",
            "[3/25][700/782] Loss_D: 1.0211 Loss_G: 1.5397\n",
            "[4/25][0/782] Loss_D: 1.1194 Loss_G: 1.4819\n",
            "[4/25][100/782] Loss_D: 1.0981 Loss_G: 1.4396\n",
            "[4/25][200/782] Loss_D: 1.1156 Loss_G: 2.0587\n",
            "[4/25][300/782] Loss_D: 1.0830 Loss_G: 1.1408\n",
            "[4/25][400/782] Loss_D: 0.9396 Loss_G: 1.7793\n",
            "[4/25][500/782] Loss_D: 0.9233 Loss_G: 2.1076\n",
            "[4/25][600/782] Loss_D: 1.1461 Loss_G: 1.5085\n",
            "[4/25][700/782] Loss_D: 0.9619 Loss_G: 1.8785\n",
            "[5/25][0/782] Loss_D: 1.3518 Loss_G: 1.2179\n",
            "[5/25][100/782] Loss_D: 0.9975 Loss_G: 1.6002\n",
            "[5/25][200/782] Loss_D: 0.8901 Loss_G: 1.8849\n",
            "[5/25][300/782] Loss_D: 1.1080 Loss_G: 0.8982\n",
            "[5/25][400/782] Loss_D: 0.7549 Loss_G: 1.7985\n",
            "[5/25][500/782] Loss_D: 1.4683 Loss_G: 1.2303\n",
            "[5/25][600/782] Loss_D: 0.9008 Loss_G: 1.6569\n",
            "[5/25][700/782] Loss_D: 1.1000 Loss_G: 2.8667\n",
            "[6/25][0/782] Loss_D: 1.5755 Loss_G: 1.7770\n",
            "[6/25][100/782] Loss_D: 1.0929 Loss_G: 3.0059\n",
            "[6/25][200/782] Loss_D: 1.1346 Loss_G: 2.4774\n",
            "[6/25][300/782] Loss_D: 0.7720 Loss_G: 1.7670\n",
            "[6/25][400/782] Loss_D: 0.8675 Loss_G: 1.4528\n",
            "[6/25][500/782] Loss_D: 0.8598 Loss_G: 3.1632\n",
            "[6/25][600/782] Loss_D: 0.7758 Loss_G: 1.8614\n",
            "[6/25][700/782] Loss_D: 0.9559 Loss_G: 2.8352\n",
            "[7/25][0/782] Loss_D: 0.7160 Loss_G: 1.7950\n",
            "[7/25][100/782] Loss_D: 0.8910 Loss_G: 2.0195\n",
            "[7/25][200/782] Loss_D: 1.0599 Loss_G: 1.8309\n",
            "[7/25][300/782] Loss_D: 0.8813 Loss_G: 1.4259\n",
            "[7/25][400/782] Loss_D: 2.0802 Loss_G: 2.3779\n",
            "[7/25][500/782] Loss_D: 1.1188 Loss_G: 0.5508\n",
            "[7/25][600/782] Loss_D: 0.6989 Loss_G: 2.2958\n",
            "[7/25][700/782] Loss_D: 0.8420 Loss_G: 1.2401\n",
            "[8/25][0/782] Loss_D: 1.1618 Loss_G: 3.7353\n",
            "[8/25][100/782] Loss_D: 0.7874 Loss_G: 2.0685\n",
            "[8/25][200/782] Loss_D: 1.4042 Loss_G: 3.0399\n",
            "[8/25][300/782] Loss_D: 0.7834 Loss_G: 1.7561\n",
            "[8/25][400/782] Loss_D: 1.6283 Loss_G: 0.9194\n",
            "[8/25][500/782] Loss_D: 0.7262 Loss_G: 2.4215\n",
            "[8/25][600/782] Loss_D: 0.6747 Loss_G: 2.2628\n",
            "[8/25][700/782] Loss_D: 0.9594 Loss_G: 3.0653\n",
            "[9/25][0/782] Loss_D: 0.7084 Loss_G: 2.4385\n",
            "[9/25][100/782] Loss_D: 0.6721 Loss_G: 2.3589\n",
            "[9/25][200/782] Loss_D: 0.7750 Loss_G: 1.6775\n",
            "[9/25][300/782] Loss_D: 1.1764 Loss_G: 4.4564\n",
            "[9/25][400/782] Loss_D: 0.6870 Loss_G: 1.8121\n",
            "[9/25][500/782] Loss_D: 1.4521 Loss_G: 1.1660\n",
            "[9/25][600/782] Loss_D: 1.1116 Loss_G: 1.1804\n",
            "[9/25][700/782] Loss_D: 0.7123 Loss_G: 1.7686\n",
            "[10/25][0/782] Loss_D: 1.0810 Loss_G: 2.8496\n",
            "[10/25][100/782] Loss_D: 0.6648 Loss_G: 2.3956\n",
            "[10/25][200/782] Loss_D: 0.6449 Loss_G: 2.7768\n",
            "[10/25][300/782] Loss_D: 0.6525 Loss_G: 2.3782\n",
            "[10/25][400/782] Loss_D: 0.7044 Loss_G: 2.8629\n",
            "[10/25][500/782] Loss_D: 1.0529 Loss_G: 1.5909\n",
            "[10/25][600/782] Loss_D: 0.6670 Loss_G: 2.1117\n",
            "[10/25][700/782] Loss_D: 0.6626 Loss_G: 2.1689\n",
            "[11/25][0/782] Loss_D: 0.7349 Loss_G: 2.3561\n",
            "[11/25][100/782] Loss_D: 0.6643 Loss_G: 2.2343\n",
            "[11/25][200/782] Loss_D: 1.3044 Loss_G: 1.9748\n",
            "[11/25][300/782] Loss_D: 0.8185 Loss_G: 1.8243\n",
            "[11/25][400/782] Loss_D: 0.6730 Loss_G: 2.2170\n",
            "[11/25][500/782] Loss_D: 0.7930 Loss_G: 1.6620\n",
            "[11/25][600/782] Loss_D: 0.8186 Loss_G: 2.2772\n",
            "[11/25][700/782] Loss_D: 0.6503 Loss_G: 2.3809\n",
            "[12/25][0/782] Loss_D: 0.7485 Loss_G: 2.4883\n",
            "[12/25][100/782] Loss_D: 0.6568 Loss_G: 2.7206\n",
            "[12/25][200/782] Loss_D: 0.7014 Loss_G: 2.1352\n",
            "[12/25][300/782] Loss_D: 0.6974 Loss_G: 2.3668\n",
            "[12/25][400/782] Loss_D: 0.6710 Loss_G: 2.2335\n",
            "[12/25][500/782] Loss_D: 1.2615 Loss_G: 5.5040\n",
            "[12/25][600/782] Loss_D: 0.6668 Loss_G: 2.4263\n",
            "[12/25][700/782] Loss_D: 0.7736 Loss_G: 2.8868\n",
            "[13/25][0/782] Loss_D: 0.8681 Loss_G: 3.7431\n",
            "[13/25][100/782] Loss_D: 0.8297 Loss_G: 2.6599\n",
            "[13/25][200/782] Loss_D: 0.7493 Loss_G: 2.6280\n",
            "[13/25][300/782] Loss_D: 0.6928 Loss_G: 2.7068\n",
            "[13/25][400/782] Loss_D: 0.6973 Loss_G: 2.6782\n",
            "[13/25][500/782] Loss_D: 0.6450 Loss_G: 2.4845\n",
            "[13/25][600/782] Loss_D: 0.6834 Loss_G: 2.6405\n",
            "[13/25][700/782] Loss_D: 0.6575 Loss_G: 2.9994\n",
            "[14/25][0/782] Loss_D: 0.7827 Loss_G: 2.7476\n",
            "[14/25][100/782] Loss_D: 0.7111 Loss_G: 2.5523\n",
            "[14/25][200/782] Loss_D: 0.6902 Loss_G: 2.4683\n",
            "[14/25][300/782] Loss_D: 0.6622 Loss_G: 2.5625\n",
            "[14/25][400/782] Loss_D: 0.6456 Loss_G: 2.7161\n",
            "[14/25][500/782] Loss_D: 1.1976 Loss_G: 3.1607\n",
            "[14/25][600/782] Loss_D: 0.6406 Loss_G: 2.7611\n",
            "[14/25][700/782] Loss_D: 0.7352 Loss_G: 2.8069\n",
            "[15/25][0/782] Loss_D: 0.7305 Loss_G: 3.3425\n",
            "[15/25][100/782] Loss_D: 1.0552 Loss_G: 1.4093\n",
            "[15/25][200/782] Loss_D: 0.7077 Loss_G: 2.0039\n",
            "[15/25][300/782] Loss_D: 0.6880 Loss_G: 2.3350\n",
            "[15/25][400/782] Loss_D: 0.6702 Loss_G: 2.8591\n",
            "[15/25][500/782] Loss_D: 0.9386 Loss_G: 2.0537\n",
            "[15/25][600/782] Loss_D: 0.6488 Loss_G: 2.7774\n",
            "[15/25][700/782] Loss_D: 0.6769 Loss_G: 3.1286\n",
            "[16/25][0/782] Loss_D: 0.6583 Loss_G: 1.8996\n",
            "[16/25][100/782] Loss_D: 0.7383 Loss_G: 1.8768\n",
            "[16/25][200/782] Loss_D: 0.6472 Loss_G: 2.6550\n",
            "[16/25][300/782] Loss_D: 0.6738 Loss_G: 2.3769\n",
            "[16/25][400/782] Loss_D: 0.6366 Loss_G: 2.3839\n",
            "[16/25][500/782] Loss_D: 0.9573 Loss_G: 1.7926\n",
            "[16/25][600/782] Loss_D: 0.7798 Loss_G: 2.3576\n",
            "[16/25][700/782] Loss_D: 0.6349 Loss_G: 3.0455\n",
            "[17/25][0/782] Loss_D: 0.6810 Loss_G: 2.7197\n",
            "[17/25][100/782] Loss_D: 0.6770 Loss_G: 2.3536\n",
            "[17/25][200/782] Loss_D: 1.1115 Loss_G: 1.5448\n",
            "[17/25][300/782] Loss_D: 0.6474 Loss_G: 2.6222\n",
            "[17/25][400/782] Loss_D: 0.8634 Loss_G: 1.6244\n",
            "[17/25][500/782] Loss_D: 0.6578 Loss_G: 2.2975\n",
            "[17/25][600/782] Loss_D: 0.7659 Loss_G: 1.6470\n",
            "[17/25][700/782] Loss_D: 0.6758 Loss_G: 2.4213\n",
            "[18/25][0/782] Loss_D: 1.3363 Loss_G: 4.6755\n",
            "[18/25][100/782] Loss_D: 0.6618 Loss_G: 2.1928\n",
            "[18/25][200/782] Loss_D: 0.7213 Loss_G: 2.4725\n",
            "[18/25][300/782] Loss_D: 0.8053 Loss_G: 1.6683\n",
            "[18/25][400/782] Loss_D: 0.6482 Loss_G: 2.1512\n",
            "[18/25][500/782] Loss_D: 0.6571 Loss_G: 2.3617\n",
            "[18/25][600/782] Loss_D: 0.7342 Loss_G: 1.8232\n",
            "[18/25][700/782] Loss_D: 0.6436 Loss_G: 2.6297\n",
            "[19/25][0/782] Loss_D: 0.6477 Loss_G: 2.4943\n",
            "[19/25][100/782] Loss_D: 0.6419 Loss_G: 2.5062\n",
            "[19/25][200/782] Loss_D: 0.7563 Loss_G: 2.8365\n",
            "[19/25][300/782] Loss_D: 0.8978 Loss_G: 1.9435\n",
            "[19/25][400/782] Loss_D: 0.6758 Loss_G: 3.0808\n",
            "[19/25][500/782] Loss_D: 0.6561 Loss_G: 2.2778\n",
            "[19/25][600/782] Loss_D: 0.7285 Loss_G: 2.5504\n",
            "[19/25][700/782] Loss_D: 0.7049 Loss_G: 1.9911\n",
            "[20/25][0/782] Loss_D: 0.8794 Loss_G: 3.0409\n",
            "[20/25][100/782] Loss_D: 0.7572 Loss_G: 2.1722\n",
            "[20/25][200/782] Loss_D: 0.6410 Loss_G: 2.4129\n",
            "[20/25][300/782] Loss_D: 0.7199 Loss_G: 1.7401\n",
            "[20/25][400/782] Loss_D: 0.6945 Loss_G: 2.6684\n",
            "[20/25][500/782] Loss_D: 0.6800 Loss_G: 2.8007\n",
            "[20/25][600/782] Loss_D: 0.6882 Loss_G: 1.9379\n",
            "[20/25][700/782] Loss_D: 0.6313 Loss_G: 2.2549\n",
            "[21/25][0/782] Loss_D: 0.6959 Loss_G: 2.2281\n",
            "[21/25][100/782] Loss_D: 0.6147 Loss_G: 2.7685\n",
            "[21/25][200/782] Loss_D: 0.6655 Loss_G: 2.7510\n",
            "[21/25][300/782] Loss_D: 0.7066 Loss_G: 2.6212\n",
            "[21/25][400/782] Loss_D: 0.6305 Loss_G: 3.0493\n",
            "[21/25][500/782] Loss_D: 0.8529 Loss_G: 1.6203\n",
            "[21/25][600/782] Loss_D: 0.6631 Loss_G: 2.4367\n",
            "[21/25][700/782] Loss_D: 0.6800 Loss_G: 1.9248\n",
            "[22/25][0/782] Loss_D: 1.1303 Loss_G: 3.4779\n",
            "[22/25][100/782] Loss_D: 0.6329 Loss_G: 2.2021\n",
            "[22/25][200/782] Loss_D: 0.6812 Loss_G: 2.1605\n",
            "[22/25][300/782] Loss_D: 0.6578 Loss_G: 2.5127\n",
            "[22/25][400/782] Loss_D: 0.6295 Loss_G: 2.6771\n",
            "[22/25][500/782] Loss_D: 0.6376 Loss_G: 2.3552\n",
            "[22/25][600/782] Loss_D: 0.6989 Loss_G: 2.5472\n",
            "[22/25][700/782] Loss_D: 0.6451 Loss_G: 2.6576\n",
            "[23/25][0/782] Loss_D: 0.6627 Loss_G: 2.7373\n",
            "[23/25][100/782] Loss_D: 0.6264 Loss_G: 2.9248\n",
            "[23/25][200/782] Loss_D: 0.7111 Loss_G: 2.4880\n",
            "[23/25][300/782] Loss_D: 0.9470 Loss_G: 3.1354\n",
            "[23/25][400/782] Loss_D: 0.8024 Loss_G: 2.0134\n",
            "[23/25][500/782] Loss_D: 0.6137 Loss_G: 2.6222\n",
            "[23/25][600/782] Loss_D: 0.7002 Loss_G: 2.5237\n",
            "[23/25][700/782] Loss_D: 0.6885 Loss_G: 2.4399\n",
            "[24/25][0/782] Loss_D: 0.6711 Loss_G: 2.5980\n",
            "[24/25][100/782] Loss_D: 0.6658 Loss_G: 2.2012\n",
            "[24/25][200/782] Loss_D: 1.1509 Loss_G: 1.0592\n",
            "[24/25][300/782] Loss_D: 0.6527 Loss_G: 2.8310\n",
            "[24/25][400/782] Loss_D: 0.7524 Loss_G: 2.7211\n",
            "[24/25][500/782] Loss_D: 0.8615 Loss_G: 2.6036\n",
            "[24/25][600/782] Loss_D: 0.6733 Loss_G: 2.1404\n",
            "[24/25][700/782] Loss_D: 0.6514 Loss_G: 2.0956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.7 Save and Evaluate Results\n",
        "torch.save(netG.state_dict(), \"./results/netG.pth\")\n",
        "torch.save(netD.state_dict(), \"./results/netD.pth\")"
      ],
      "metadata": {
        "id": "gIbo0P4pijpC"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}